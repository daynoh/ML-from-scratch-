{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e129eea0",
   "metadata": {},
   "source": [
    "### A simple regression NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44351f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41410eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### using Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c105ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import standard_scaler\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "#### using Sequential API\n",
    "\n",
    "housing = fetch_california_housing\n",
    "\n",
    "X_train_full,X_test,y_train,y_test = train_test_split(housing.data, housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "### Initializing the model using sequential Api\n",
    "\n",
    "model = keras.models.Sequential(\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1))\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\", optimizer =\"sgd\" )\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data = (X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:3]\n",
    "\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "### using functional API creating a deep and wide NN\n",
    "\n",
    "> This may be especially useful when you want to build a network that can take up different features but output should \n",
    "be the same\n",
    "> maybe useful for creating RL enviroments \n",
    "\n",
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(10,activation = 'relu')\n",
    "hidden2 = keras.layers.Dense(10,activation = 'relu')\n",
    "\n",
    "concat = keras.layers.Concatenate()([input_,hidden2])\n",
    "\n",
    "output_ = keras.layers.Dense(1)(concat)\n",
    "\n",
    "\n",
    "model = keras.model(inputs = [input_], outputs = [output])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = keras.optimizers.SGD(lr = 1e-3))\n",
    "\n",
    "history = model.fit(X_train,y_train, validation_data = (X_valid, y_valid)\n",
    "\n",
    "### Using Subclassing API\n",
    "\n",
    "> useful when model is a bit more complex (some models require loops or other dynamic behaviours\n",
    "\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units = 10, activation = relu, *kwargs):\n",
    "        super().__init__(*kwargs): #handles standard args\n",
    "        self.hidden1 = keras.layers.Dense(units, activation = activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation = activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A,hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        \n",
    "\n",
    "model = WideAndDeepModel()\n",
    "\n",
    "> downside is that model created this way cannot be saved and inspected \n",
    "\n",
    "### Saving and restoring models\n",
    "\n",
    "model.save(\"my_keras_model.h5\")\n",
    "\n",
    "# to load\n",
    "\n",
    "model.load(\"my_keras_model.h5\")\n",
    "\n",
    "### Creating Model check points \n",
    "\n",
    "### using callBacks to act as checkpoints\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 10, callbacks = [checkpoint_cb])\n",
    "\n",
    "# if you are using a validation set you can ask keras to only save the best\n",
    "\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only = True)\n",
    "\n",
    "model = keras.models.load_model('my_keras_model.h5') # rolls back to the best\n",
    "\n",
    "\n",
    "### Implementing Early stopping strategy\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs= 100, \n",
    "                   validation_data= (X_valid, y_valid),\n",
    "                   callbacks = [checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "### using TensorBoard for live visualization of results\n",
    "\n",
    "import os\n",
    "\n",
    "# Creating directory to save the logs\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    \n",
    "    run_id = time.strftime(\"run_%Y_%m_%d - %H_%M_%S\")\n",
    "    \n",
    "    return os.path.join(roor_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "#### \n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[tensorboard_cb])\n",
    "# used to initialize tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "### HyperParameter tuning using Randomized search CV\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distribs = {\n",
    "\"n_hidden\": [0, 1, 2, 3],\n",
    "\"n_neurons\": np.arange(1, 100),\n",
    "\"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10,\n",
    "cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "rnd_search_cv.best_params_\n",
    "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}\n",
    "rnd_search_cv.best_score_\n",
    "-0.3189529188278931\n",
    "model = rnd_search_cv.best_estimator_.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
