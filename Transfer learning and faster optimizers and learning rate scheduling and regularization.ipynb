{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0adc7",
   "metadata": {},
   "source": [
    "### Implementing transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d941e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting model to use\n",
    "\n",
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "\n",
    "## Creating a new model based on A\n",
    "\n",
    "model_B = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "##The above code makes model A and B have the same weights \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cae8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To avoid the above scenerio\n",
    "\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0761a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### making reused layers untrainable\n",
    "\n",
    "for layer in model_A_clone.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "    \n",
    "    \n",
    "model_A_clone.compile(loss = \"binary_crossentropy\", optimizer = \"sgd\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de25d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the model\n",
    "\n",
    "history = model_A_clone.fit(X_train_b, y_train_B, epochs = 4 , validation_data = [X_valid_B, y_valid_B])\n",
    "optimizer = keras.optimizers.SGD(lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8969ca0",
   "metadata": {},
   "source": [
    "### Faster optimizers\n",
    "#### momentum optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431d171b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m, momentum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr = 0.0001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb3ea4",
   "metadata": {},
   "source": [
    "### Nesterov \n",
    "\n",
    "update of momentum reduces the oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ef709",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr = 0.001, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d8daf",
   "metadata": {},
   "source": [
    "### Ada Grad\n",
    "- achieves faster converges as it directs gradient vector along the steepest slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74968c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879df488",
   "metadata": {},
   "source": [
    "### RMSProp\n",
    "\n",
    "- Ada grad runs the risk of slowing down a bit too fast and never converging to global minimum\n",
    "\n",
    "RMS prop fixes this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e715391",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr = 0.0001, rho = 0.9)\n",
    "\n",
    "#rho = decay rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa8cae",
   "metadata": {},
   "source": [
    "### Adam and Nadam\n",
    "\n",
    "Adam - adaptive moment estimation (combines both rMsprop and momentum optimization)\n",
    "\n",
    "- Typically the best\n",
    "\n",
    "\n",
    "\n",
    "NaDam is adam with nestrov trick sometimes converges earlier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr = 0.0001, beta_1 = 0.9, beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42b311",
   "metadata": {},
   "source": [
    "### learning rate scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447556c5",
   "metadata": {},
   "source": [
    "#### Power scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb3b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr = 0.01, decay = k1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f452f",
   "metadata": {},
   "source": [
    "#### Exponential scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41934c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0,s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return 0.01 * 0.1 **(epoch/s)\n",
    "    return exponential_decay_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e381c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.exponential_decay.<locals>.exponential_decay_fn(epoch)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_decay(10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a320865",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0 = 0.01, s= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82490914",
   "metadata": {},
   "source": [
    "### Create a learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "history = model.fit(X_train, y_train , callbacks = [lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcade9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using schedules class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811da50c",
   "metadata": {},
   "source": [
    "### Performance Scheduling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c55fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size =\n",
    "32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27bbc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0228121",
   "metadata": {},
   "source": [
    "### Regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b822d",
   "metadata": {},
   "source": [
    "##### Lasso and ridge regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25feede",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation = \"elu\", kernel_initializer = \"he_normal\",\n",
    "                          kernel_regularizers = keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aaaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                            activation=\"elu\",\n",
    "                            kernel_initializer=\"he_normal\",\n",
    "                            kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\",\n",
    "    kernel_initializer=\"glorot_uniform\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f4010",
   "metadata": {},
   "source": [
    "### using dropout as a regularization technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade27228",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [28,28]),\n",
    "    keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(300, activation = \"elu\", kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(300, activation = \"elu\", kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(10, activation =\"softmax\")\n",
    "\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
